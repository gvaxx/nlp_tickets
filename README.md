# NLP Jira - –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤

–ü—Ä–æ–µ–∫—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∑–∞–¥–∞—á, –æ—Ç–∑—ã–≤–æ–≤, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤) —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤** - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
- **–£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é UMAP
- **–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é HDBSCAN
- **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è** - –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ** - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:
```bash
git clone <repository-url>
cd nlp_tickets
```

2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash
pip install -r requirements.txt
```

## üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä

```python
from text_clustering_pipeline import TextClusteringPipeline
import pandas as pd

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
data = {
    'id': [1, 2, 3, 4],
    'text': [
        '–ò—Å–ø—Ä–∞–≤–∏—Ç—å –±–∞–≥ —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π',
        '–ü—Ä–æ–±–ª–µ–º–∞ —Å –≤—Ö–æ–¥–æ–º –≤ —Å–∏—Å—Ç–µ–º—É',
        '–î–æ–±–∞–≤–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç –≤ CSV',
        '–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö'
    ]
}
df = pd.DataFrame(data)

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
pipeline = TextClusteringPipeline()
result = pipeline.fit(df)

# –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
pipeline.get_cluster_samples(result)
```

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### TextClusteringPipeline

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å 'ai-forever/FRIDA' –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–æ–µ —Ä–µ—à–µ–Ω–∏–µ, —Ç–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'.

```python
pipeline = TextClusteringPipeline(
    embedding_model_name='ai-forever/FRIDA',
    random_seed=42
)
```

**–ú–µ—Ç–æ–¥—ã:**
- `fit()` - –ø–æ–ª–Ω—ã–π pipeline –æ–±—É—á–µ–Ω–∏—è
- `predict()` - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
- `visualize()` - —Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
- `get_cluster_samples()` - –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤

### –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏

1. **–≠–º–±–µ–¥–¥–∏–Ω–≥–∏** - SentenceTransformers —Å–æ–∑–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
2. **UMAP** - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (–æ–±—ã—á–Ω–æ –¥–æ 5D)
3. **HDBSCAN** - –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø
4. **–ê–Ω–∞–ª–∏–∑** - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–ü–æ—Å–ª–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ:

- **DataFrame** —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: `id`, `text`, `cluster_id`, `cluster_confidence`
- **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é** –≤ 2D –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
- **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É** –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- **–ü—Ä–∏–º–µ—Ä—ã** —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### UMAP (—É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏)
```python
pipeline.reduce_dimensions(
    n_components=5,      # —Ü–µ–ª–µ–≤–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    n_neighbors=15,      # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π
    min_dist=0.0,        # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    metric='cosine'      # –º–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
)
```

### HDBSCAN (–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è)
```python
pipeline.cluster(
    min_cluster_size=50,    # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞
    min_samples=10,         # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π
    metric='euclidean',     # –º–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    cluster_selection_method='eom'  # –º–µ—Ç–æ–¥ –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
)
```

## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

- **2D scatter plot** - –∫–ª–∞—Å—Ç–µ—Ä—ã –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ UMAP
- **Bar charts** - —Ä–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- **Heatmaps** - –ø–æ—Ö–æ–∂–µ—Å—Ç—å –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏
- **Hierarchy** - –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

## üîç –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

- **cluster_id = -1** - —à—É–º–æ–≤—ã–µ —Ç–æ—á–∫–∏ (outliers)
- **cluster_confidence** - —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –∫–ª–∞—Å—Ç–µ—Ä—É (0-1)
- **–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤** - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ

## üõ†Ô∏è –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- –£–º–µ–Ω—å—à–∏—Ç–µ `batch_size` –≤ `create_embeddings()`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `use_multiprocessing=False`
- –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞

### –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ/–º–∞–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ `min_cluster_size` –∏ `min_samples`
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è `n_components` –≤ UMAP

## üìù –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞

- `text_clustering_pipeline.py` - –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
- `requirements.txt` - –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ –≤–µ—Ç–∫—É –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License
